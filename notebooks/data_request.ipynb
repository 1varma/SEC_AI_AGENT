{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf4c5752",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashish-varma-j/Desktop/SEC_AI_AGENT/agent/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from edgar import Company, set_identity\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from threading import Lock\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "set_identity(\"Ashish juttua@clarkson.edu\") \n",
    "RAW_DATA_DIR = \"../data/data_raw_html\"\n",
    "MAX_REQ_PER_SEC = 10 \n",
    "\n",
    "# Rate Limiter to ensure we don't get banned while moving fast\n",
    "class RateLimiter:\n",
    "    def __init__(self, rate_limit):\n",
    "        self.rate_limit = rate_limit\n",
    "        self.tokens = rate_limit\n",
    "        self.last_update = time.time()\n",
    "        self.lock = Lock()\n",
    "\n",
    "    def wait_for_token(self):\n",
    "        with self.lock:\n",
    "            while True:\n",
    "                now = time.time()\n",
    "                elapsed = now - self.last_update\n",
    "                if elapsed > 1.0:\n",
    "                    self.tokens = self.rate_limit\n",
    "                    self.last_update = now\n",
    "                if self.tokens > 0:\n",
    "                    self.tokens -= 1\n",
    "                    return\n",
    "                time.sleep(0.01)\n",
    "\n",
    "limiter = RateLimiter(MAX_REQ_PER_SEC)\n",
    "\n",
    "def get_sp500_tickers():\n",
    "    print(\"Fetching S&P 500 list...\")\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/91.0.4472.124 Safari/537.36\"}\n",
    "    try:\n",
    "        tables = pd.read_html(requests.get(url, headers=headers).text)\n",
    "        return [t.replace('.', '-') for t in tables[0]['Symbol'].tolist()]\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching list: {e}\")\n",
    "        return []\n",
    "\n",
    "def download_html(ticker):\n",
    "    try:\n",
    "        limiter.wait_for_token()\n",
    "        company = Company(ticker)\n",
    "        \n",
    "        # Get list of filings (Metadata only, fast)\n",
    "        filings = company.get_filings(form=[\"10-K\", \"10-Q\"])\n",
    "        if not filings: return f\"{ticker}: No filings.\"\n",
    "\n",
    "        save_dir = os.path.join(RAW_DATA_DIR, ticker)\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        count = 0\n",
    "        for filing in filings:\n",
    "            date = filing.filing_date\n",
    "            form = filing.form.replace(\"/\", \"-\")\n",
    "            \n",
    "            # Filename: TICKER_FORM_DATE.html\n",
    "            fname = f\"{ticker}_{form}_{date}.html\"\n",
    "            fpath = os.path.join(save_dir, fname)\n",
    "            \n",
    "            if os.path.exists(fpath):\n",
    "                continue\n",
    "            \n",
    "            limiter.wait_for_token()\n",
    "            try:\n",
    "                # FAST: Just grab raw HTML string, no parsing\n",
    "                html_content = filing.html() \n",
    "                if html_content:\n",
    "                    with open(fpath, \"w\", encoding=\"utf-8\") as f:\n",
    "                        f.write(html_content)\n",
    "                    count += 1\n",
    "            except Exception:\n",
    "                pass\n",
    "                \n",
    "        return f\"{ticker}: Downloaded {count} raw HTML files.\"\n",
    "    except Exception as e:\n",
    "        return f\"{ticker}: Error {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49163dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching S&P 500 list...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_61102/3073526350.py:42: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(requests.get(url, headers=headers).text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting RAW Download for 503 companies ---\n",
      "ABNB: Downloaded 20 raw HTML files.\n",
      "GOOGL: Downloaded 44 raw HTML files.\n",
      "ACN: Downloaded 67 raw HTML files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABBV: Downloaded 53 raw HTML files.\n",
      "AMD: Downloaded 112 raw HTML files.\n",
      "ALLE: Downloaded 48 raw HTML files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AKAM: Downloaded 104 raw HTML files.\n",
      "ABT: Downloaded 102 raw HTML files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALGN: Downloaded 103 raw HTML files.\n",
      "AOS: Downloaded 103 raw HTML files.\n",
      "GOOG: Downloaded 44 raw HTML files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: Downloaded 109 raw HTML files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADBE: Downloaded 109 raw HTML files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALB: Downloaded 111 raw HTML files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\t\t\t\t\t\t\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\t\t\t\t\t\t\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\t\t\t\t\t\t\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\t\t\t\t\t\t\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tIRS NUMBER'\n",
      "Subheader 'COMPANY DATA' not found in header ']\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tIRS NUMBER'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMM: Downloaded 101 raw HTML files.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    tickers = get_sp500_tickers()\n",
    "    if not tickers: return\n",
    "    \n",
    "    print(f\"--- Starting RAW Download for {len(tickers)} companies ---\")\n",
    "    \n",
    "    # 20 threads to keep the network busy\n",
    "    with ThreadPoolExecutor(max_workers=20) as executor:\n",
    "        futures = {executor.submit(download_html, t): t for t in tickers}\n",
    "        for future in as_completed(futures):\n",
    "            print(future.result())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64db7e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
