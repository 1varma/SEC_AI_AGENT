{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3891d877-dcbe-442b-ad99-6397bf9e2b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "from edgar import Company, set_identity\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from threading import Lock\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400e3cf6-13bc-48b9-a742-06d0a0aa3773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION ---\n",
    "# 1. Identity (REQUIRED by SEC)\n",
    "set_identity(\"Ashish juttua@clarkson.edu\") \n",
    "\n",
    "# 2. AWS Settings\n",
    "# CHANGE THIS to a unique name (S3 buckets must be globally unique)\n",
    "BUCKET_NAME = \"sec-filings-raw-data-ashish-v1\" \n",
    "AWS_REGION = \"us-east-1\"\n",
    "S3_FOLDER = \"raw_html/\"\n",
    "\n",
    "# 3. Performance Settings\n",
    "MAX_REQ_PER_SEC = 10  # SEC Limit\n",
    "MAX_WORKERS = 8       # Number of parallel threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aad74ad-45e5-4e12-84fd-5ad2b12786e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- RATE LIMITER ---\n",
    "class RateLimiter:\n",
    "    def __init__(self, rate_limit):\n",
    "        self.rate_limit = rate_limit\n",
    "        self.tokens = rate_limit\n",
    "        self.last_update = time.time()\n",
    "        self.lock = Lock()\n",
    "\n",
    "    def wait_for_token(self):\n",
    "        with self.lock:\n",
    "            while True:\n",
    "                now = time.time()\n",
    "                elapsed = now - self.last_update\n",
    "                if elapsed > 1.0:\n",
    "                    self.tokens = self.rate_limit\n",
    "                    self.last_update = now\n",
    "                if self.tokens > 0:\n",
    "                    self.tokens -= 1\n",
    "                    return\n",
    "                time.sleep(0.05)\n",
    "\n",
    "limiter = RateLimiter(MAX_REQ_PER_SEC)\n",
    "s3_client = boto3.client('s3', region_name=AWS_REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a97bb8f-232c-4dba-9632-0801d088ac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_s3_bucket():\n",
    "    \"\"\"Creates the S3 bucket if it doesn't exist.\"\"\"\n",
    "    try:\n",
    "        s3_client.head_bucket(Bucket=BUCKET_NAME)\n",
    "        print(f\"âœ… Bucket '{BUCKET_NAME}' found.\")\n",
    "    except ClientError:\n",
    "        print(f\"Creating bucket '{BUCKET_NAME}'...\")\n",
    "        try:\n",
    "            if AWS_REGION == \"us-east-1\":\n",
    "                s3_client.create_bucket(Bucket=BUCKET_NAME)\n",
    "            else:\n",
    "                s3_client.create_bucket(\n",
    "                    Bucket=BUCKET_NAME,\n",
    "                    CreateBucketConfiguration={'LocationConstraint': AWS_REGION}\n",
    "                )\n",
    "            print(f\"Successfully created bucket '{BUCKET_NAME}'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"CRITICAL ERROR: Could not create bucket. {e}\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26eca85-5e77-448c-bd78-8a57909dc099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sp500_tickers():\n",
    "    \"\"\"Fetches S&P 500 list from Wikipedia.\"\"\"\n",
    "    print(\"Fetching S&P 500 list...\")\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"}\n",
    "    try:\n",
    "        tables = pd.read_html(requests.get(url, headers=headers).text)\n",
    "        tickers = [t.replace('.', '-') for t in tables[0]['Symbol'].tolist()]\n",
    "        print(f\"Loaded {len(tickers)} companies.\")\n",
    "        return tickers\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching tickers: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bceeff0-9814-48b3-88a3-545553bcf762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_file_exists_s3(key):\n",
    "    \"\"\"Checks if a file is already in S3 to skip re-downloading.\"\"\"\n",
    "    try:\n",
    "        s3_client.head_object(Bucket=BUCKET_NAME, Key=key)\n",
    "        return True\n",
    "    except ClientError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef2dad1-da30-4dda-9b1b-bc43980938da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_company(ticker):\n",
    "    \"\"\"Downloads filings for one company and uploads to S3.\"\"\"\n",
    "    try:\n",
    "        limiter.wait_for_token()\n",
    "        company = Company(ticker)\n",
    "        \n",
    "        # Get metadata for 10-K (Annual) and 10-Q (Quarterly)\n",
    "        filings = company.get_filings(form=[\"10-K\", \"10-Q\"])\n",
    "        if not filings:\n",
    "            return f\"{ticker}: No filings found.\"\n",
    "\n",
    "        upload_count = 0\n",
    "        \n",
    "        for filing in filings:\n",
    "            date = filing.filing_date\n",
    "            form = filing.form.replace(\"/\", \"-\")\n",
    "            \n",
    "            # S3 Key: raw_html/AAPL/AAPL_10-K_2023-01-01.html\n",
    "            s3_key = f\"{S3_FOLDER}{ticker}/{ticker}_{form}_{date}.html\"\n",
    "            \n",
    "            # 1. Check S3 first (Save bandwidth)\n",
    "            if check_file_exists_s3(s3_key):\n",
    "                continue\n",
    "            \n",
    "            # 2. Download Content (Respect Rate Limit)\n",
    "            limiter.wait_for_token()\n",
    "            try:\n",
    "                html_content = filing.html()\n",
    "                if html_content:\n",
    "                    # 3. Upload directly to S3\n",
    "                    s3_client.put_object(\n",
    "                        Bucket=BUCKET_NAME,\n",
    "                        Key=s3_key,\n",
    "                        Body=html_content.encode('utf-8'),\n",
    "                        ContentType='text/html'\n",
    "                    )\n",
    "                    upload_count += 1\n",
    "            except Exception as e:\n",
    "                pass\n",
    "                \n",
    "        return f\"{ticker}: Uploaded {upload_count} new filings.\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"{ticker}: Failed - {str(e)[:50]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320b6cda-a763-4261-b188-2322f01b6337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MAIN EXECUTION ---\n",
    "\n",
    "# 1. Setup Storage\n",
    "create_s3_bucket()\n",
    "\n",
    "# 2. Get Targets\n",
    "tickers = get_sp500_tickers()\n",
    "\n",
    "if tickers:\n",
    "    print(f\"--- Processing {len(tickers)} companies ---\")\n",
    "    print(f\"--- Target: s3://{BUCKET_NAME}/{S3_FOLDER} ---\")\n",
    "    \n",
    "    # 3. Run Parallel Jobs\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        future_to_ticker = {executor.submit(process_company, t): t for t in tickers}\n",
    "        \n",
    "        counter = 0\n",
    "        total = len(tickers)\n",
    "        \n",
    "        for future in as_completed(future_to_ticker):\n",
    "            counter += 1\n",
    "            result = future.result()\n",
    "            print(f\"[{counter}/{total}] {result}\")\n",
    "            \n",
    "    print(\"--- JOB COMPLETE ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fedfbf8-6be9-4e6d-92bd-3b5993334152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files in S3: 38183\n"
     ]
    }
   ],
   "source": [
    "# Check how many files are in the bucket\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(BUCKET_NAME)\n",
    "count = sum(1 for _ in bucket.objects.all())\n",
    "print(f\"Total files in S3: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e2582a-614f-4394-abae-aa526631c147",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
